{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Algorithm and Spam Detection\n",
    "\n",
    "This notebook is my implementation of the Naive Bayes algorithm for spam detection. I used the tutorial in this link as a guide: https://github.com/udacity/machine-learning/blob/master/projects/practice_projects/naive_bayes_tutorial/Naive_Bayes_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "# for importing zipfiles from url\n",
    "from requests import get\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data and import into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download zipfile from website\n",
    "data_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "request = get(data_path)\n",
    "data_downloaded = BytesIO(request.content)\n",
    "zip_file = ZipFile(data_downloaded)\n",
    "\n",
    "# reading the first file in the zip file and decode raw bytes in the string \n",
    "spam_data = zip_file.read('SMSSpamCollection').decode('utf-8')\n",
    "\n",
    "# write data to a file\n",
    "with open('spam_data.txt', 'w') as f:\n",
    "    f.write(spam_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "# Import into a pandas dataframe\n",
    "df = pd.read_csv('spam_data.txt', \n",
    "                 sep='\\t',\n",
    "                 header=None,\n",
    "                 names=['label', 'sms_message']\n",
    "                )\n",
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert string labels into binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words\n",
    "\n",
    "Machine learning algorithms needs numeric features for training. To get numeric features, use the Bag of Words model to convert the sentences into a series of columns containing the frequency of each word for each sentence in the data.\n",
    "\n",
    "The steps to convert text into features using the Bag of Words model:\n",
    "1. Convert all string into lower case form\n",
    "2. Remove all punctuations\n",
    "3. Tokenize sentences (split up sentences into individual words using a delimiter and save to list)\n",
    "4. Count occurence of each word for each sentence using data generated in 3.\n",
    "\n",
    "Example below demonstrates how to do this using the CountVectorizer class in sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 0 1 0 0 0 0 0 1]\n",
      " [0 0 1 0 1 0 0 1 0 0 2 0]\n",
      " [0 1 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 1 0 2 0 0 0 0 0 1 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>call</th>\n",
       "      <th>from</th>\n",
       "      <th>hello</th>\n",
       "      <th>home</th>\n",
       "      <th>how</th>\n",
       "      <th>me</th>\n",
       "      <th>money</th>\n",
       "      <th>now</th>\n",
       "      <th>tomorrow</th>\n",
       "      <th>win</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  call  from  hello  home  how  me  money  now  tomorrow  win  you\n",
       "0    1     0     0      1     0    1   0      0    0         0    0    1\n",
       "1    0     0     1      0     1    0   0      1    0         0    2    0\n",
       "2    0     1     0      0     0    0   1      0    1         0    0    0\n",
       "3    0     1     0      2     0    0   0      0    0         1    0    1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = ['Hello, how are you!',\n",
    "                'Win money, win from home.',\n",
    "                'Call me now.',\n",
    "                'Hello, Call hello you tomorrow?']\n",
    "\n",
    "count_vector = CountVectorizer(lowercase=True)\n",
    "\n",
    "# learn vocabulary\n",
    "count_vector.fit(documents)\n",
    "\n",
    "# transform documents to a document-term matrix, then to an array\n",
    "doc_array = count_vector.transform(documents).toarray()\n",
    "print(doc_array)\n",
    "\n",
    "# load into dataframe\n",
    "feature_names = count_vector.get_feature_names()\n",
    "frequency_matrix = pd.DataFrame(doc_array, \n",
    "                                columns=feature_names)\n",
    "frequency_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and testing\n",
    "Split training and label data into a training set (75%) and a test set (25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data size: 5572\n",
      "Training set size: 4179\n",
      "Test set size: 1393\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'],\n",
    "                                                    df['label'],\n",
    "                                                    random_state=1\n",
    "                                                   )\n",
    "\n",
    "print(\"Full data size:\", df.shape[0])\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Bag of Words processing to the split data\n",
    "We fit the vocabulary dictionary only for the training data. Here's a great explanation why we do this: https://sebastianraschka.com/faq/docs/scale-training-test.html. The basic idea is that we treat test data as new and unseen. Therefore, we cannot learn--by applying the fit() function--the vocabulary of this new data and must use the vocabulary learned from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer()\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem review\n",
    "\n",
    "The example in the tutorial is on finding the odds of a person having diabetes given that they got a positive result. Let the probability of having diabetes, denoted by $P(D)$, be 0.01. This is often referred to as the __base rate__ or the __prior__ probability. Assume that the test is %90 accurate. This means that the probability of testing positive given that you have diabetes is $P(Pos|D) = 0.9$. Alternatively, the probabily of testing negative given the person doesn't have diabetes is $P(Neg|~D) = 0.9$.\n",
    "\n",
    "The probability we are interested in is\n",
    "\n",
    "$$P(D|Pos) = \\frac{P(Pos|D)P(D)}{P(Pos)}$$\n",
    "\n",
    "$P(Pos)$ is the probability of testing positive regardless of whether you have diabetes or not. People without diabetes can still test positive because the test is imperfect. The formula for $P(Pos)$ is\n",
    "\n",
    "$$P(Pos) = P(D)P(Pos|D) + P(~D)P(Pos|~D)$$\n",
    "\n",
    "Intuitively, $P(D)P(Pos|D)$ is the probability of testing positive _and_ having diabetes. $P(~D)P(Pos|~D)$ is the probability of still testing positive _and_ not having diabetes. Their sum, therefore, is just the probability of testing positive, whether or not you have diabetes.\n",
    "\n",
    "Putting all of this together the probability of having diabetes given that you tested positive is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333336\n"
     ]
    }
   ],
   "source": [
    "prob_d = 0.01\n",
    "prob_pos_d = 0.9\n",
    "prob_neg_no_d = 0.9\n",
    "prob_pos = prob_d * prob_pos_d + (1 - prob_d) * (1 - prob_neg_no_d)\n",
    "\n",
    "prob_d_pos = (prob_pos_d * prob_d) / prob_pos\n",
    "\n",
    "print(prob_d_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asdasd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
